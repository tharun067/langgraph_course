{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Streaming\n",
        "\n",
        "## Review\n",
        "\n",
        "In module 2, covered a few ways to customize graph state and memory.\n",
        "\n",
        "We built up to a Chatbot with external memory that can sustain long-running conversations.\n",
        "\n",
        "## Goals\n",
        "\n",
        "This module will dive into `human-in-the-loop`, which builds on memory and allows users to interact directly with graphs in various ways.\n",
        "\n",
        "To set the stage for `human-in-the-loop`, we'll first dive into streaming, which provides several ways to visualize graph output (e.g., node state or chat model tokens) over the course of execution."
      ],
      "metadata": {
        "id": "kuXgRWE8JRmb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pRUXmP98JJZe"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langgraph langgraph_sdk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU \"langchain[google-genai]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPnKKQ-rJfEr",
        "outputId": "e338e821-6fad-4e24-942c-90b49c3d738d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m608.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.0/444.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Streaming\n",
        "\n",
        "LangGraph is built with [first class support for streaming](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
        "\n",
        "Let's set up our Chatbot from Module 2, and show various way to stream outputs from the graph during execution."
      ],
      "metadata": {
        "id": "dRwNoXfWJn8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"GOOGLE_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ESqvUQLJkD7",
        "outputId": "b935d8dd-ad65-4e8e-edce-0a30d4bd08fd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GOOGLE_API_KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that we use `RunnableConfig` with `call_model` to enable token-wise streaming. This is [only needed with python < 3.11](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/). We include in case you are running this notebook in CoLab, which will use python 3.x."
      ],
      "metadata": {
        "id": "y8tISybQJ3cU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph import MessagesState\n",
        "\n",
        "# LLM\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
        "\n",
        "# State\n",
        "class State(MessagesState):\n",
        "    summary: str\n",
        "\n",
        "# Define the logic to call the model\n",
        "def call_model(state: State, config: RunnableConfig):\n",
        "\n",
        "    # Get summary if it exists\n",
        "    summary = state.get(\"summary\", \"\")\n",
        "\n",
        "    # If there is summary, then we add it\n",
        "    if summary:\n",
        "\n",
        "        # Add summary to system message\n",
        "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
        "\n",
        "        # Append summary to any newer messages\n",
        "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
        "\n",
        "    else:\n",
        "        messages = state[\"messages\"]\n",
        "\n",
        "    response = model.invoke(messages, config)\n",
        "    return {\"messages\": response}\n",
        "\n",
        "def summarize_conversation(state: State):\n",
        "\n",
        "    # First, we get any existing summary\n",
        "    summary = state.get(\"summary\", \"\")\n",
        "\n",
        "    # Create our summarization prompt\n",
        "    if summary:\n",
        "\n",
        "        # A summary already exists\n",
        "        summary_message = (\n",
        "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
        "            \"Extend the summary by taking into account the new messages above:\"\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        summary_message = \"Create a summary of the conversation above:\"\n",
        "\n",
        "    # Add prompt to our history\n",
        "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
        "    response = model.invoke(messages)\n",
        "\n",
        "    # Delete all but the 2 most recent messages\n",
        "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
        "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
        "\n",
        "# Determine whether to end or summarize the conversation\n",
        "def should_continue(state: State):\n",
        "\n",
        "    \"\"\"Return the next node to execute.\"\"\"\n",
        "\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    # If there are more than six messages, then we summarize the conversation\n",
        "    if len(messages) > 6:\n",
        "        return \"summarize_conversation\"\n",
        "\n",
        "    # Otherwise we can just end\n",
        "    return END\n",
        "\n",
        "# Define a new graph\n",
        "workflow = StateGraph(State)\n",
        "workflow.add_node(\"conversation\", call_model)\n",
        "workflow.add_node(summarize_conversation)\n",
        "\n",
        "# Set the entrypoint as conversation\n",
        "workflow.add_edge(START, \"conversation\")\n",
        "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
        "workflow.add_edge(\"summarize_conversation\", END)\n",
        "\n",
        "# Compile\n",
        "memory = MemorySaver()\n",
        "graph = workflow.compile(checkpointer=memory)\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "Q3nDJwOAJxZD",
        "outputId": "833486c1-abde-4533-8bb9-b694a86abc11"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Streaming full state\n",
        "\n",
        "Now, let's talk about ways to [stream our graph state](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
        "\n",
        "`.stream` and `.astream` are sync and async methods for streaming back results.\n",
        "\n",
        "LangGraph supports a few [different streaming modes](https://langchain-ai.github.io/langgraph/how-tos/stream-values/) for [graph state](https://langchain-ai.github.io/langgraph/how-tos/stream-values/):\n",
        "\n",
        "* `values`: This streams the full state of the graph after each node is called.\n",
        "* `updates`: This streams updates to the state of the graph after each node is called.\n",
        "\n",
        "![values_vs_updates.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf892d24625a201744e5_streaming1.png)\n",
        "\n",
        "Let's look at `stream_mode=\"updates\"`.\n",
        "\n",
        "Because we stream with `updates`, we only see updates to the state after node in the graph is run.\n",
        "\n",
        "Each `chunk` is a dict with `node_name` as the key and the updated state as the value."
      ],
      "metadata": {
        "id": "JwEPThdkKf5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a thread\n",
        "config = {\"configurable\":{\"thread_id\":\"1\"}}\n",
        "# Start conversation\n",
        "for chunk in graph.stream({\"messages\":[HumanMessage(content=\"hi! I'm Tharun\")]},config,stream_mode=\"updates\"):\n",
        "  print(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_xqPAKAKbgY",
        "outputId": "859539f5-fc65-447a-b700-1a0648a7dcdd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'conversation': {'messages': AIMessage(content=\"Hi Tharun! Nice to meet you.\\n\\nI'm an AI assistant. How can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--5a160a39-0aed-4fb4-aebe-84e6c5bffdc4-0', usage_metadata={'input_tokens': 8, 'output_tokens': 328, 'total_tokens': 336, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 304}})}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now just print the state update"
      ],
      "metadata": {
        "id": "xtMmdtYKLDh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in graph.stream({\"messages\":[HumanMessage(content=\"hi! I'm Tharun\")]},config,stream_mode=\"updates\"):\n",
        "  chunk[\"conversation\"][\"messages\"].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2jUXPbPK_LB",
        "outputId": "ce9c5a19-2d39-49c1-d65d-7e52f990eb5c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hi Tharun! It's good to hear from you again.\n",
            "\n",
            "How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can see `stream_mode=\"values\"`.\n",
        "\n",
        "This is the `full state` of the graph after the `conversation` node is called."
      ],
      "metadata": {
        "id": "xR7GzHYRLY-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start conversation, again\n",
        "config = {\"configurable\":{\"thread_id\":\"2\"}}\n",
        "# Start conversation\n",
        "input_message = HumanMessage(content=\"hi! I'm Tharun\")\n",
        "for event in graph.stream({\"messages\":[input_message]},config,stream_mode=\"values\"):\n",
        "  for m in event['messages']:\n",
        "    m.pretty_print()\n",
        "  print(\"---\"*25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PowLfyEVLP8E",
        "outputId": "6a815cf2-6418-4a80-b936-b6fa56e9cc2c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "hi! I'm Tharun\n",
            "---------------------------------------------------------------------------\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "hi! I'm Tharun\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hi Tharun! Nice to meet you.\n",
            "\n",
            "I'm an AI assistant, here to help you with whatever you need. How can I assist you today?\n",
            "---------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Streaming tokens\n",
        "\n",
        "We often want to stream more than graph state.\n",
        "\n",
        "In particular, with chat model calls it is common to stream the tokens as they are generated.\n",
        "\n",
        "We can do this [using the `.astream_events` method](https://langchain-ai.github.io/langgraph/how-tos/streaming-from-final-node/#stream-outputs-from-the-final-node), which streams back events as they happen inside nodes!\n",
        "\n",
        "Each event is a dict with a few keys:\n",
        "\n",
        "* `event`: This is the type of event that is being emitted.\n",
        "* `name`: This is the name of event.\n",
        "* `data`: This is the data associated with the event.\n",
        "* `metadata`: Contains`langgraph_node`, the node emitting the event.\n",
        "\n",
        "Let's have a look."
      ],
      "metadata": {
        "id": "BXbThtnhMLkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\":{\"thread_id\":\"3\"}}\n",
        "input_message = HumanMessage(content=\"Tell me about the CSK IPL team\")\n",
        "async for event in graph.astream_events({\"messages\":[input_message]},config,version=\"v2\"):\n",
        "  print(f\"Node: {event['metadata'].get('langgraph_node','')}.Type: {event['event']}. Name: {event['name']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z3dA3pwL_W_",
        "outputId": "941a87fa-a4c1-44e6-bf50-2b9e9cfb02dc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node: .Type: on_chain_start. Name: LangGraph\n",
            "Node: conversation.Type: on_chain_start. Name: conversation\n",
            "Node: conversation.Type: on_chat_model_start. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation.Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation.Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation.Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation.Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation.Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation.Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation.Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation.Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation.Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation.Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation.Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation.Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation.Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation.Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation.Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation.Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation.Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation.Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation.Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation.Type: on_chat_model_end. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation.Type: on_chain_start. Name: should_continue\n",
            "Node: conversation.Type: on_chain_end. Name: should_continue\n",
            "Node: conversation.Type: on_chain_stream. Name: conversation\n",
            "Node: conversation.Type: on_chain_end. Name: conversation\n",
            "Node: .Type: on_chain_stream. Name: LangGraph\n",
            "Node: .Type: on_chain_end. Name: LangGraph\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The central point is that tokens from chat models within your graph have the `on_chat_model_stream` type.\n",
        "\n",
        "We can use `event['metadata']['langgraph_node']` to select the node to stream from.\n",
        "\n",
        "And we can use `event['data']` to get the actual data for each event, which in this case is an `AIMessageChunk`."
      ],
      "metadata": {
        "id": "3eWK8FZUNFv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "node_to_stream = 'conversation'\n",
        "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
        "input_message = HumanMessage(content=\"Tell me about the CSK IPL team\")\n",
        "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
        "    # Get chat model tokens from a particular node\n",
        "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
        "        print(event[\"data\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBSRTRnUM6F_",
        "outputId": "6e8248e8-5450-4da9-9994-634bcfd6e353"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'chunk': AIMessageChunk(content=\"The Chennai Super Kings (CSK) are one of the most successful and beloved franchises in the Indian Premier League (IPL). Here's a detailed look at the team:\\n\\n**1. Franchise Overview:**\\n\\n*   **Full Name:** Chennai Super\", additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--7c9a6e68-a1dd-4a9a-a560-60b92320ba4b', usage_metadata={'input_tokens': 8, 'output_tokens': 1317, 'total_tokens': 1325, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1266}})}\n",
            "{'chunk': AIMessageChunk(content=' Kings\\n*   **City:** Chennai, Tamil Nadu\\n*   **Owner:** Chennai Super Kings Cricket Ltd. (a subsidiary of India Cements, led by N. Srinivasan)\\n*   **Home Ground:** M. A', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--7c9a6e68-a1dd-4a9a-a560-60b92320ba4b', usage_metadata={'input_token_details': {'cache_read': 0}, 'output_tokens': 48, 'input_tokens': 0, 'total_tokens': 48, 'output_token_details': {'reasoning': 0}})}\n",
            "{'chunk': AIMessageChunk(content='. Chidambaram Stadium (Chepauk), Chennai\\n*   **Team Colors:** Primarily yellow, with blue accents.\\n*   **Mascot:** A roaring lion, often associated with the \"Whistle Podu\"', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--7c9a6e68-a1dd-4a9a-a560-60b92320ba4b', usage_metadata={'input_token_details': {'cache_read': 0}, 'output_tokens': 48, 'input_tokens': 0, 'total_tokens': 48, 'output_token_details': {'reasoning': 0}})}\n",
            "{'chunk': AIMessageChunk(content=' (Whistle Up!) slogan.\\n*   **Captain:** MS Dhoni (since the inception, except for a brief period in 2022 when Ravindra Jadeja captained).\\n*   **Head Coach:** Stephen Fleming (a', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--7c9a6e68-a1dd-4a9a-a560-60b92320ba4b', usage_metadata={'input_token_details': {'cache_read': 0}, 'output_tokens': 49, 'input_tokens': 0, 'total_tokens': 49, 'output_token_details': {'reasoning': 0}})}\n",
            "{'chunk': AIMessageChunk(content=' long-standing and highly successful partnership with Dhoni).\\n\\n**2. Key Achievements & Records:**\\n\\n*   **IPL Titles:** 5 (2010, 2011, 2018, 202', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--7c9a6e68-a1dd-4a9a-a560-60b92320ba4b', usage_metadata={'input_token_details': {'cache_read': 0}, 'output_tokens': 50, 'input_tokens': 0, 'total_tokens': 50, 'output_token_details': {'reasoning': 0}})}\n",
            "{'chunk': AIMessageChunk(content='1, 2023) – Joint-most successful team in IPL history, alongside Mumbai Indians.\\n*   **Champions League T20 Titles:** 2 (2010, 2014)\\n*   ', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--7c9a6e68-a1dd-4a9a-a560-60b92320ba4b', usage_metadata={'input_token_details': {'cache_read': 0}, 'output_tokens': 49, 'input_tokens': 0, 'total_tokens': 49, 'output_token_details': {'reasoning': 0}})}\n",
            "{'chunk': AIMessageChunk(content=\"**Consistency:** CSK holds the record for the most playoff appearances (12 out of 14 seasons played) and the most IPL final appearances (10). They have never finished outside the top 4 in any season they've participated\", additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--7c9a6e68-a1dd-4a9a-a560-60b92320ba4b', usage_metadata={'input_token_details': {'cache_read': 0}, 'output_tokens': 49, 'input_tokens': 0, 'total_tokens': 49, 'output_token_details': {'reasoning': 0}})}\n",
            "{'chunk': AIMessageChunk(content=' in.\\n\\n**3. Team Philosophy & Playing Style:**\\n\\n*   **Experience Over Youth:** CSK has often been dubbed \"Dad\\'s Army\" due to their preference for experienced players, even those in the twilight of their careers.', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--7c9a6e68-a1dd-4a9a-a560-60b92320ba4b', usage_metadata={'input_token_details': {'cache_read': 0}, 'output_tokens': 48, 'input_tokens': 0, 'total_tokens': 48, 'output_token_details': {'reasoning': 0}})}\n",
            "{'chunk': AIMessageChunk(content=' This strategy has consistently paid off, as these players bring calm, tactical acumen, and big-match temperament.\\n*   **All-Rounders:** The team heavily relies on a strong core of all-rounders who can contribute with both bat and', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--7c9a6e68-a1dd-4a9a-a560-60b92320ba4b', usage_metadata={'input_token_details': {'cache_read': 0}, 'output_tokens': 51, 'input_tokens': 0, 'total_tokens': 51, 'output_token_details': {'reasoning': 0}})}\n",
            "{'chunk': AIMessageChunk(content=' ball, providing flexibility and depth.\\n*   **Home Advantage:** Chepauk is a fortress for CSK. The pitch is typically slow and spin-friendly, which perfectly suits their bowling attack, often featuring multiple quality spinners.\\n*', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--7c9a6e68-a1dd-4a9a-a560-60b92320ba4b', usage_metadata={'input_token_details': {'cache_read': 0}, 'output_tokens': 48, 'input_tokens': 0, 'total_tokens': 48, 'output_token_details': {'reasoning': 0}})}\n",
            "{'chunk': AIMessageChunk(content='   **Calm Leadership:** Under MS Dhoni and Stephen Fleming, the team is known for its calm, process-oriented approach. They rarely panic and trust their plans and players.\\n*   **Strong Core:** CSK believes in retaining a core group', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--7c9a6e68-a1dd-4a9a-a560-60b92320ba4b', usage_metadata={'input_token_details': {'cache_read': 0}, 'output_tokens': 49, 'input_tokens': 0, 'total_tokens': 49, 'output_token_details': {'reasoning': 0}})}\n",
            "{'chunk': AIMessageChunk(content=' of players for multiple seasons, fostering team cohesion and understanding.\\n\\n**4. Iconic Figures:**\\n\\n*   **MS Dhoni (Captain & \"Thala\"):** The heart and soul of CSK. Dhoni\\'s captaincy, tactical brilliance', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--7c9a6e68-a1dd-4a9a-a560-60b92320ba4b', usage_metadata={'input_token_details': {'cache_read': 0}, 'output_tokens': 48, 'input_tokens': 0, 'total_tokens': 48, 'output_token_details': {'reasoning': 0}})}\n",
            "{'chunk': AIMessageChunk(content=', finishing skills, and calm demeanor have been instrumental in the team\\'s success. He is revered as \"Thala\" (leader) by the fans.\\n*   **Suresh Raina (\"Chinna Thala\"):** Often called \"Mr', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--7c9a6e68-a1dd-4a9a-a560-60b92320ba4b', usage_metadata={'input_token_details': {'cache_read': 0}, 'output_tokens': 50, 'input_tokens': 0, 'total_tokens': 50, 'output_token_details': {'reasoning': 0}})}\n",
            "{'chunk': AIMessageChunk(content='. IPL\" and \"Chinna Thala\" (junior leader), Raina was a consistent run-scorer and a vital part of CSK\\'s batting lineup for many years.\\n*   **Ravindra Jadeja:** A dynamic all-rounder,', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--7c9a6e68-a1dd-4a9a-a560-60b92320ba4b', usage_metadata={'input_token_details': {'cache_read': 0}, 'output_tokens': 49, 'input_tokens': 0, 'total_tokens': 49, 'output_token_details': {'reasoning': 0}})}\n",
            "{'chunk': AIMessageChunk(content=' exceptional fielder, and a key spinner who has been with the team for a long time.\\n*   **Dwayne Bravo:** The West Indian all-rounder was a death-bowling specialist and a powerful lower-order hitter, contributing significantly to', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--7c9a6e68-a1dd-4a9a-a560-60b92320ba4b', usage_metadata={'input_token_details': {'cache_read': 0}, 'output_tokens': 50, 'input_tokens': 0, 'total_tokens': 50, 'output_token_details': {'reasoning': 0}})}\n",
            "{'chunk': AIMessageChunk(content=' many victories.\\n*   **Stephen Fleming (Coach):** His long-standing partnership with Dhoni has created a stable and successful management structure.\\n\\n**5. The Ban and Comeback:**\\n\\n*   CSK, along with Rajasthan', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--7c9a6e68-a1dd-4a9a-a560-60b92320ba4b', usage_metadata={'input_token_details': {'cache_read': 0}, 'output_tokens': 48, 'input_tokens': 0, 'total_tokens': 48, 'output_token_details': {'reasoning': 0}})}\n",
            "{'chunk': AIMessageChunk(content=' Royals, was suspended for two years (2016 and 2017) due to the involvement of their owners in the 2013 IPL betting scandal.\\n*   Their return in 2018', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--7c9a6e68-a1dd-4a9a-a560-60b92320ba4b', usage_metadata={'input_token_details': {'cache_read': 0}, 'output_tokens': 49, 'input_tokens': 0, 'total_tokens': 49, 'output_token_details': {'reasoning': 0}})}\n",
            "{'chunk': AIMessageChunk(content=' was highly anticipated and culminated in a fairytale victory, winning the IPL title against Sunrisers Hyderabad, which further cemented their legendary status and fan loyalty.\\n\\n**6. Fan Base (\"Whistle Podu\"):**\\n\\n*   CSK boasts', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--7c9a6e68-a1dd-4a9a-a560-60b92320ba4b', usage_metadata={'input_token_details': {'cache_read': 0}, 'output_tokens': 49, 'input_tokens': 0, 'total_tokens': 49, 'output_token_details': {'reasoning': 0}})}\n",
            "{'chunk': AIMessageChunk(content=' one of the most passionate and loyal fan bases in the IPL, often referred to as the \"Yellow Army.\"\\n*   The \"Whistle Podu\" (Whistle Up!) slogan and anthem are iconic, creating an electrifying atmosphere at their', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--7c9a6e68-a1dd-4a9a-a560-60b92320ba4b', usage_metadata={'input_token_details': {'cache_read': 0}, 'output_tokens': 50, 'input_tokens': 0, 'total_tokens': 50, 'output_token_details': {'reasoning': 0}})}\n",
            "{'chunk': AIMessageChunk(content=' home ground and wherever they play. Their fans travel in large numbers, making every match feel like a home game.\\n\\n**7. Overall Legacy:**\\n\\nThe Chennai Super Kings are more than just a cricket team; they are an emotion for', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run--7c9a6e68-a1dd-4a9a-a560-60b92320ba4b', usage_metadata={'input_token_details': {'cache_read': 0}, 'output_tokens': 48, 'input_tokens': 0, 'total_tokens': 48, 'output_token_details': {'reasoning': 0}})}\n",
            "{'chunk': AIMessageChunk(content=' millions of fans. Their consistent success, the charismatic leadership of MS Dhoni, their unique team philosophy, and their incredible comeback story have made them one of the most beloved and enduring franchises in the history of T20 cricket.', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--7c9a6e68-a1dd-4a9a-a560-60b92320ba4b', usage_metadata={'input_token_details': {'cache_read': 0}, 'output_tokens': 46, 'input_tokens': 0, 'total_tokens': 46, 'output_token_details': {'reasoning': 0}})}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see above, just use the `chunk` key to get the `AIMessageChunk`."
      ],
      "metadata": {
        "id": "Z0eDZZcKNWZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
        "input_message = HumanMessage(content=\"Tell me about the CSK IPL team\")\n",
        "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
        "    # Get chat model tokens from a particular node\n",
        "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
        "        data = event[\"data\"]\n",
        "        print(data[\"chunk\"].content, end=\"|\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LnIdinSNM4w",
        "outputId": "7166f488-1907-416e-f745-5d9e0415c09f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Chennai Super Kings (CSK) are one of the most successful and beloved franchises in the Indian Premier League (IPL). Here's a detailed look at the team:\n",
            "\n",
            "**1. Franchise Overview:**\n",
            "\n",
            "*   **Full Name:** Chennai Super| Kings\n",
            "*   **City:** Chennai, Tamil Nadu\n",
            "*   **Owner:** Chennai Super Kings Cricket Ltd. (a subsidiary of India Cements, led by N. Srinivasan)\n",
            "*   **Home Ground:** M. A|. Chidambaram Stadium (Chepauk), Chennai\n",
            "*   **Team Colors:** Primarily yellow, with blue accents.\n",
            "*   **Mascot:** A roaring lion, often associated with the \"Whistle Podu\"| (Whistle Up!) slogan.\n",
            "*   **Captain:** MS Dhoni (since the inception, except for a brief period in 2022 when Ravindra Jadeja captained).\n",
            "*   **Head Coach:** Stephen Fleming (a| long-standing and highly successful partnership with Dhoni).\n",
            "\n",
            "**2. Key Achievements & Records:**\n",
            "\n",
            "*   **IPL Titles:** 5 (2010, 2011, 2018, 202|1, 2023) – Joint-most successful team in IPL history, alongside Mumbai Indians.\n",
            "*   **Champions League T20 Titles:** 2 (2010, 2014)\n",
            "*   |**Consistency:** CSK holds the record for the most playoff appearances (12 out of 14 seasons played) and the most IPL final appearances (10). They have never finished outside the top 4 in any season they've participated| in.\n",
            "\n",
            "**3. Team Philosophy & Playing Style:**\n",
            "\n",
            "*   **Experience Over Youth:** CSK has often been dubbed \"Dad's Army\" due to their preference for experienced players, even those in the twilight of their careers.| This strategy has consistently paid off, as these players bring calm, tactical acumen, and big-match temperament.\n",
            "*   **All-Rounders:** The team heavily relies on a strong core of all-rounders who can contribute with both bat and| ball, providing flexibility and depth.\n",
            "*   **Home Advantage:** Chepauk is a fortress for CSK. The pitch is typically slow and spin-friendly, which perfectly suits their bowling attack, often featuring multiple quality spinners.\n",
            "*|   **Calm Leadership:** Under MS Dhoni and Stephen Fleming, the team is known for its calm, process-oriented approach. They rarely panic and trust their plans and players.\n",
            "*   **Strong Core:** CSK believes in retaining a core group| of players for multiple seasons, fostering team cohesion and understanding.\n",
            "\n",
            "**4. Iconic Figures:**\n",
            "\n",
            "*   **MS Dhoni (Captain & \"Thala\"):** The heart and soul of CSK. Dhoni's captaincy, tactical brilliance|, finishing skills, and calm demeanor have been instrumental in the team's success. He is revered as \"Thala\" (leader) by the fans.\n",
            "*   **Suresh Raina (\"Chinna Thala\"):** Often called \"Mr|. IPL\" and \"Chinna Thala\" (junior leader), Raina was a consistent run-scorer and a vital part of CSK's batting lineup for many years.\n",
            "*   **Ravindra Jadeja:** A dynamic all-rounder,| exceptional fielder, and a key spinner who has been with the team for a long time.\n",
            "*   **Dwayne Bravo:** The West Indian all-rounder was a death-bowling specialist and a powerful lower-order hitter, contributing significantly to| many victories.\n",
            "*   **Stephen Fleming (Coach):** His long-standing partnership with Dhoni has created a stable and successful management structure.\n",
            "\n",
            "**5. The Ban and Comeback:**\n",
            "\n",
            "*   CSK, along with Rajasthan| Royals, was suspended for two years (2016 and 2017) due to the involvement of their owners in the 2013 IPL betting scandal.\n",
            "*   Their return in 2018| was highly anticipated and culminated in a fairytale victory, winning the IPL title against Sunrisers Hyderabad, which further cemented their legendary status and fan loyalty.\n",
            "\n",
            "**6. Fan Base (\"Whistle Podu\"):**\n",
            "\n",
            "*   CSK boasts| one of the most passionate and loyal fan bases in the IPL, often referred to as the \"Yellow Army.\"\n",
            "*   The \"Whistle Podu\" (Whistle Up!) slogan and anthem are iconic, creating an electrifying atmosphere at their| home ground and wherever they play. Their fans travel in large numbers, making every match feel like a home game.\n",
            "\n",
            "**7. Overall Legacy:**\n",
            "\n",
            "The Chennai Super Kings are more than just a cricket team; they are an emotion for| millions of fans. Their consistent success, the charismatic leadership of MS Dhoni, their unique team philosophy, and their incredible comeback story have made them one of the most beloved and enduring franchises in the history of T20 cricket.|"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Streaming with LangGraph API\n",
        "\n",
        "**⚠️ DISCLAIMER**\n",
        "\n",
        "Since the filming of these videos, we've updated Studio so that it can be run locally and opened in your browser. This is now the preferred way to run Studio (rather than using the Desktop App as shown in the video). See documentation [here](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server) on the local development server and [here](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server). To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
        "\n",
        "```\n",
        "langgraph dev\n",
        "```\n",
        "\n",
        "You should see the following output:\n",
        "```\n",
        "- 🚀 API: http://127.0.0.1:2024\n",
        "- 🎨 Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
        "- 📚 API Docs: http://127.0.0.1:2024/docs\n",
        "```\n",
        "\n",
        "Open your browser and navigate to the Studio UI: `https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`.\n",
        "\n",
        "The LangGraph API [supports editing graph state](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_edit_state/#initial-invocation)."
      ],
      "metadata": {
        "id": "tqKGeLcxNw8C"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sd3EizGhNh1y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}